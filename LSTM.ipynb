{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d5b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:51:03.915469: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 14:51:04.029505: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-04 14:51:04.033592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-04 14:51:04.033606: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-04 14:51:04.054466: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-04 14:51:04.500809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 14:51:04.500850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-04 14:51:04.500853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn \n",
    "%matplotlib inline \n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import log_loss\n",
    "from sentence_transformers import SentenceTransformer \n",
    "# import torch \n",
    "# import os\n",
    "import random \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, f1_score\n",
    "# import urduhack #for pre processing Urdu Text\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "random.seed(42)\n",
    "#other required libraries will be imported at the time of requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6e2a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      " Training Data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>happiness</th>\n",
       "      <th>neutral</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>محبت پردے میں نفرت کرنےوالو</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>حامد میر خوشی اس کا ذمہ دار حکومت خوش</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>اس نئے سال شام سپاہی قاتل لارنس شکل میں شعبے ب...</td>\n",
       "      <td>135</td>\n",
       "      <td>526</td>\n",
       "      <td>0.256167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>کچھ اس طرح سے فلم جا سکتے لیکن میں سب سے یقینا...</td>\n",
       "      <td>117</td>\n",
       "      <td>435</td>\n",
       "      <td>0.268349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>رون ہاورڈ اس ایڈیٹرز صرف اتنا کرنا جس کا تھا ا...</td>\n",
       "      <td>84</td>\n",
       "      <td>304</td>\n",
       "      <td>0.275410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>نتائج دنیا کو حیرت میں ڈال سکتی ھے نتائج دس اق...</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>0.271429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ہم غصے خراب موڈ خوشی غمی سب میں چپلی کباب</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>اب ایسی حیرت وارفتگی کو کیا کہیے دعا کو ہاتھ ا...</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>0.264151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>آپ اپنی آنکھوں سے نفرت پٹی اتاریں شائد اندازہ ...</td>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>0.232143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>حیرت</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  disgust  fear  sadness  surprise  happiness  neutral  \\\n",
       "0      0        0     0        1         1          0        0   \n",
       "1      0        0     0        0         0          1        0   \n",
       "2      0        0     0        0         0          0        1   \n",
       "3      0        0     0        0         0          0        1   \n",
       "4      0        0     0        0         0          0        1   \n",
       "5      0        0     0        0         0          0        0   \n",
       "6      0        0     0        0         1          0        0   \n",
       "7      0        0     0        1         1          0        0   \n",
       "8      0        0     0        1         1          0        0   \n",
       "9      0        0     0        0         1          0        0   \n",
       "\n",
       "                                           Sentences  word_count  char_count  \\\n",
       "0                       محبت پردے میں نفرت کرنےوالو            5          23   \n",
       "1             حامد میر خوشی اس کا ذمہ دار حکومت خوش            9          29   \n",
       "2  اس نئے سال شام سپاہی قاتل لارنس شکل میں شعبے ب...         135         526   \n",
       "3  کچھ اس طرح سے فلم جا سکتے لیکن میں سب سے یقینا...         117         435   \n",
       "4  رون ہاورڈ اس ایڈیٹرز صرف اتنا کرنا جس کا تھا ا...          84         304   \n",
       "5  نتائج دنیا کو حیرت میں ڈال سکتی ھے نتائج دس اق...          19          69   \n",
       "6         ہم غصے خراب موڈ خوشی غمی سب میں چپلی کباب           10          32   \n",
       "7  اب ایسی حیرت وارفتگی کو کیا کہیے دعا کو ہاتھ ا...          14          52   \n",
       "8  آپ اپنی آنکھوں سے نفرت پٹی اتاریں شائد اندازہ ...          13          55   \n",
       "9                                              حیرت            1           4   \n",
       "\n",
       "   word_density  \n",
       "0      0.208333  \n",
       "1      0.300000  \n",
       "2      0.256167  \n",
       "3      0.268349  \n",
       "4      0.275410  \n",
       "5      0.271429  \n",
       "6      0.303030  \n",
       "7      0.264151  \n",
       "8      0.232143  \n",
       "9      0.200000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################\n",
      " Testing Data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>happiness</th>\n",
       "      <th>neutral</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>بچھڑنے والوں کا کیسے نہ غم کیا جائے بوجھ ایسا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>اس خوفناک اذیت تشدد گندگی میں بدترین ڈی تعاون ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>تمام ناقص جاز رپ آف افسوس میری وقت پسندیدہ ڈائ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>اس فلم ساتھ راجر ایوری کوئنتن تارتانتینو سے ہد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>جنگلی جانوروں غیر ملکی خطوں غیر معمولی ثقافتوں...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>لڑکی سیریل بلاتکاری روشندان ذریعے اس گھور رہا ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>سر خدا کا واسطہ راولپنڈی پے توجہ دلوائیں راجہ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>عزیز مجھے میں کہاں سے آغاز کروں والد بھی لڑکی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>بہت آسان ھائی ذرا دماغ کو نفرت بغض عینک اتار ک...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>میں نے سپائک ان فلم مختلف عنوان منتخب کیا تھا ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  disgust  fear  sadness  surprise  happiness  neutral  \\\n",
       "0      0        0     0        1         0          0        0   \n",
       "1      0        0     0        0         0          0        1   \n",
       "2      0        0     0        0         0          0        1   \n",
       "3      0        0     0        0         0          0        1   \n",
       "4      0        0     0        0         0          0        1   \n",
       "5      0        0     0        0         0          0        1   \n",
       "6      0        0     0        1         1          0        0   \n",
       "7      0        0     0        0         0          0        1   \n",
       "8      0        0     0        1         0          0        0   \n",
       "9      0        0     0        0         0          0        1   \n",
       "\n",
       "                                           Sentences  \n",
       "0  بچھڑنے والوں کا کیسے نہ غم کیا جائے بوجھ ایسا ...  \n",
       "1  اس خوفناک اذیت تشدد گندگی میں بدترین ڈی تعاون ...  \n",
       "2  تمام ناقص جاز رپ آف افسوس میری وقت پسندیدہ ڈائ...  \n",
       "3  اس فلم ساتھ راجر ایوری کوئنتن تارتانتینو سے ہد...  \n",
       "4  جنگلی جانوروں غیر ملکی خطوں غیر معمولی ثقافتوں...  \n",
       "5  لڑکی سیریل بلاتکاری روشندان ذریعے اس گھور رہا ...  \n",
       "6  سر خدا کا واسطہ راولپنڈی پے توجہ دلوائیں راجہ ...  \n",
       "7  عزیز مجھے میں کہاں سے آغاز کروں والد بھی لڑکی ...  \n",
       "8  بہت آسان ھائی ذرا دماغ کو نفرت بغض عینک اتار ک...  \n",
       "9  میں نے سپائک ان فلم مختلف عنوان منتخب کیا تھا ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reading the data \n",
    "df_train=pd.read_csv(\"Train_Clean.csv\")\n",
    "df_test=pd.read_csv(\"Test_Clean.csv\")\n",
    "print(\"############################################\\n Training Data\\n\")\n",
    "display(df_train.head(10))\n",
    "print(\"############################################\\n Testing Data\\n\")\n",
    "display(df_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b50e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Flatten, Dense, Embedding\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f7883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into 80:20 ratio \n",
    "x_train_val=df_train[\"Sentences\"]\n",
    "y_train_val=df_train[[\"anger\",\"disgust\",\"fear\",\"sadness\",\"surprise\",\"happiness\",\"neutral\"]]\n",
    "x_test=df_test[\"Sentences\"]\n",
    "y_test=df_test[[\"anger\",\"disgust\",\"fear\",\"sadness\",\"surprise\",\"happiness\",\"neutral\"]]\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train_val,y_train_val,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ab7339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data is\n",
      "x_train------> (6240,)\n",
      "y_train------> (6240, 7)\n",
      "Shape of test data is\n",
      "x_test------> (1950,)\n",
      "y_test------> (1950, 7)\n",
      "Shape of Validation data is\n",
      "x_val------> (1560,)\n",
      "y_val------> (1560, 7)\n"
     ]
    }
   ],
   "source": [
    "#shape of training data \n",
    "print(\"Shape of train data is\\nx_train------>\",x_train.shape)\n",
    "print(\"y_train------>\",y_train.shape)\n",
    "print(\"Shape of test data is\\nx_test------>\",x_test.shape)\n",
    "print(\"y_test------>\",y_test.shape)\n",
    "print(\"Shape of Validation data is\\nx_val------>\",x_val.shape)\n",
    "print(\"y_val------>\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dea7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1500\n",
    "max_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8448ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(x_train_val.values)\n",
    "\n",
    "x_train_converted = tokenizer.texts_to_sequences(x_train.values)\n",
    "x_train_converted = pad_sequences(x_train_converted, maxlen=max_len)\n",
    "\n",
    "x_test_converted = tokenizer.texts_to_sequences(x_test.values)\n",
    "x_test_converted = pad_sequences(x_test_converted, maxlen=max_len)\n",
    "x_val_converted = tokenizer.texts_to_sequences(x_val.values)\n",
    "x_val_converted = pad_sequences(x_val_converted, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f8695bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train data : (6240, 1500)\n",
      "The shape of target of the training : (6240, 7)\n",
      "The shape of test data : (1950, 1500)\n",
      "The shaoe of target of the test:  (1950, 7)\n",
      "The shape of validation data:  (1560, 1500)\n",
      "The shape of target of validation :  (1560, 7)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of train data :', x_train_converted.shape)\n",
    "print('The shape of target of the training :', y_train.shape)\n",
    "print('The shape of test data :', x_test_converted.shape)\n",
    "print(\"The shaoe of target of the test: \", y_test.shape)\n",
    "print(\"The shape of validation data: \",x_val_converted.shape)\n",
    "print(\"The shape of target of validation : \",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2295e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Conv1D, BatchNormalization, LSTM, Bidirectional\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Input, Flatten, Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "878c56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1500, 100)         150000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 1500, 100)        0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1500, 256)        234496    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 1500, 128)        164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 32)                20608     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 569,687\n",
      "Trainable params: 569,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "model = Sequential()\n",
    "model.add(Embedding(1500, 100,input_length = x_train_converted.shape[1]))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(128,return_sequences=True,dropout=0.3,recurrent_dropout=0.3)))\n",
    "model.add(Bidirectional(LSTM(64,return_sequences=True,dropout=0.3,recurrent_dropout=0.3)))\n",
    "model.add(LSTM(32, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',metrics='accuracy', optimizer='Adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62a2eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"/home/shirish/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/shirish/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/shirish/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/shirish/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/shirish/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_288986/4236323937.py\", line 3, in <cell line: 3>\n      histroy = model.fit(x_train_converted,y_train, validation_data=(x_val_converted,y_val),epochs=200,callbacks=[reduce_lr,early_stoping],verbose=1,batch_size=34)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_1/embedding_1/embedding_lookup'\nindices[5,1481] = 1503 is not in [0, 1500)\n\t [[{{node sequential_1/embedding_1/embedding_lookup}}]] [Op:__inference_train_function_34654]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-05\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m early_stoping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, baseline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m histroy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_converted\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val_converted\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stoping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m34\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/embedding_1/embedding_lookup' defined at (most recent call last):\n    File \"/home/shirish/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/shirish/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/shirish/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/shirish/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/shirish/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_288986/4236323937.py\", line 3, in <cell line: 3>\n      histroy = model.fit(x_train_converted,y_train, validation_data=(x_val_converted,y_val),epochs=200,callbacks=[reduce_lr,early_stoping],verbose=1,batch_size=34)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shirish/anaconda3/lib/python3.9/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_1/embedding_1/embedding_lookup'\nindices[5,1481] = 1503 is not in [0, 1500)\n\t [[{{node sequential_1/embedding_1/embedding_lookup}}]] [Op:__inference_train_function_34654]"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5,min_lr=1e-05,verbose=1)\n",
    "early_stoping = EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=5,verbose=1,mode=\"auto\", baseline=None,restore_best_weights=True)\n",
    "histroy = model.fit(x_train_converted,y_train, validation_data=(x_val_converted,y_val),epochs=200,callbacks=[reduce_lr,early_stoping],verbose=1,batch_size=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3ef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
